{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación de un Data Lake\n",
    "### Autor: Víctor Manuel Rodríguez Loyola\n",
    "### ITESM CEM\n",
    "\n",
    "## Contenido:\n",
    "1. Materiales utilizados\n",
    "2. Instalación de Raspberry Pi OS\n",
    "3. Configuraciones básicas\n",
    "    * Cambiar nombre del host\n",
    "    * Establecer una dirección IP estática\n",
    "    * Agregar hosts\n",
    "    * Activar SSH\n",
    "4. Establecer una conexión SSH\n",
    "5. Creación de llaves SSH\n",
    "\n",
    "## Materiales utilizados:\n",
    "   * 3 o más Raspberry Pi model 3B+\n",
    "   * 3 o más Tarjeta Micro SD de 32 Gb en adelante\n",
    "   * 1 switch\n",
    "   * 3 o más Cable Ethernet\n",
    "   * 3 o más Fuente de alimentación con 2A de corriente de salida\n",
    "   * 1 case para montar el cluster\n",
    "   * 1 monitor, teclado y mouse\n",
    "    \n",
    "## Procedimiento\n",
    "\n",
    "### Instalación de Raspberry Pi OS\n",
    "\n",
    "El primer paso es verificar que sus tarjetas MicroSD estén formateadas.\n",
    "\n",
    "Es recomendable hacer el formateo utilizando aplicaciones como **MicroSD Formatter**, disponible [en este enlace.](https://www.sdcard.org/downloads/formatter/)\n",
    "    \n",
    "Una vez formateadas todas las MicroSD, ingrese al sitio oficial de descargas de Raspberry Pi (https://www.raspberrypi.org/downloads/) y descargue **Noobs** en formato ZIP. \n",
    "\n",
    "Ya con Noobs descargado, conecte la MicroSD a su computadora y extraiga el archivo ZIP ahí. Posteriormente, desconecte la MicroSD y conéctela a una de las Raspberry Pi. \n",
    "\n",
    "Ahora, conecte el monitor, teclado, mouse y fuente de alimentación a la Raspberry Pi para comenzar con la instalación del sistema operativo. Espere unos segundos para que se reconozcan los archivos de la Micro SD.\n",
    "\n",
    "#### Nota: Verifique que al momento de conectar su Raspberry Pi a la corriente, encienda un LED verde y uno rojo. El LED rojo indica que la Raspberry Pi está conectada a la corriente, y el LED verde indica que se está leyendo la MicroSD correctamente.\n",
    "\n",
    "Deberá observar el **menú de instalación**. Seleccione el sistema operativo a instalar (en este caso Raspberry Pi OS o Raspbian), el idioma en que desee que se instale y presione el botón de _instalar_ en la parte superior izquierda. El proceso de instalación durará unos minutos, asegúrse de que la Raspberry Pi se mantenga conectada a la corriente.  \n",
    "\n",
    "Una vez terminada la instalación, apague la Raspberry Pi y desconéctela de la corriente. Asegúrese de que el LED verde esté apagado antes de desconectar.\n",
    "\n",
    "Este proceso de instalación se tiene que hacer para cada Raspberry Pi. Para evitar repetir este proceso, es posible clonar el contenido de la MicroSD mediante la creación de una **imagen**. Esto puede hacerse con aplicaciones como **Win32 Disk Imager**, disponible [en este enlace.](https://win32diskimager.download/)\n",
    "\n",
    "Al clonar la MicroSD con Raspberry Pi OS instalado, únicamente tendrá que instalar la imagen el el resto de las tarjetas MicroSD y podrá arrancar todas las Raspberry Pi con el sistema operativo instalado. Después de hacer este proceso, verifique que el resto de las Raspberry Pi arranquen de forma correcta. \n",
    "\n",
    "### Configuraciones básicas\n",
    "\n",
    "Para poder conectar las Raspberry Pi en el cluster es necesario realizar estas configuraciones en cada una de ellas: \n",
    "\n",
    "#### Cambiar el nombre del host\n",
    "Cambiar el nombre del host nos ayudará a identificar más fácilmente a cada Raspberry Pi al momento de trabajar con el cluster, ya que por defecto tienen el nombre de _raspberrypi_.\n",
    "\n",
    "Para cambiar el nombre del host, abra una terminal y teclee el comando  \n",
    "\n",
    "```sudo nano /etc/hostname```\n",
    "\n",
    "\n",
    "Se abrirá un archivo con el nombre actual del host. Reemplace el nombre. Una vez modificado _hostname_, presione Ctrl+O para guardar los cambios y Ctrl+X para salir del archivo. \n",
    "\n",
    "Puede comprobar que el nombre del host se modificó correctamente con el comando ```hostname```\n",
    "\n",
    "En este caso se asignaron los nombres de host a las Raspberry Pi de la siguiente manera:\n",
    "* master\n",
    "* slave01\n",
    "* slave02\n",
    "\n",
    "#### Establecer una dirección IP estática\n",
    "\n",
    "Esto se hace accediendo al archivo _/etc/dhcpd.conf_ y buscando el apartado donde se encuentre la configuración de la interfaz Ethernet, normalmente mostrada como ```interface eth0```. Configure la dirección IP estática,así como las direcciones de Gateway y de DNS con los siguientes comandos:\n",
    "\n",
    "```static ip_address=192.168.1.101/24```  \n",
    "\n",
    "```static routers=192.168.1.254```  \n",
    "\n",
    "```static domain_name_servers=192.168.1.1 8.8.8.8 fd51:42f8:caae:d92e::1```  \n",
    "\n",
    "En este caso se asignaron las direcciones IP de la siguiente manera:\n",
    "\n",
    "* master:  192.198.1.101/24\n",
    "* slave01: 192.198.1.102/24\n",
    "* slave02: 192.198.1.103/24\n",
    "\n",
    "#### Agregar host\n",
    "Para trabajar con el cluster será necesario agregar los otros host que conformarán el mismo. \n",
    "\n",
    "Abra una terminal y teclee el comando\n",
    "```sudo nano /etc/hosts```\n",
    "\n",
    "En el archivo que se abre tendrá que añadir el nombre y la dirección IP de todos los host que conforman el cluster.\n",
    "\n",
    "En este caso, la configuración quedó de la siguiente manera:\n",
    "\n",
    "```192.198.1.101   master```  \n",
    "```192.198.1.102   slave01```  \n",
    "```192.198.1.103   slave02```  \n",
    "```192.198.1.104   slave03```\n",
    "\n",
    "#### Activar SSH\n",
    "Para activar la interfaz SSH, navague hasta la configuración entrando a menú principal -> Preferencias -> Configuración de Raspberry Pi. \n",
    "\n",
    "Una vez dentro, vaya a la pestaña de Interfaces, localice la interfaz _SSH_ y asegúrese de que se encuentre activada. \n",
    "\n",
    "![act_ssh](https://github.com/RD13p/Proyecto_DataLake/blob/master/act-ssh.png?raw=true)\n",
    "\n",
    "### Establecer una conexión SSH\n",
    "\n",
    "Una vez activado el SSH, utilizaremos los **alias SSH** para conectar todas las Raspberry Pi entre sí. Para crear los alias, ingrese al archivo ```~/.ssh/config``` escribiendo el comando ```nano .ssh/config```. En caso de que ese archivo y/o la carpeta no existan, puede crearlos dentro del directorio ```/home/pi```. Una vez dentro del archivo, deberá añadir las siguientes líneas:\n",
    "\n",
    "```Host master```   \n",
    "```User pi```  \n",
    "```Hostname 192.168.1.101```\n",
    "\n",
    "Estos son los mismos datos contenidos en el archivo ```hosts``` creado anteriormente. Deberá colocar esas líneas por cada una de las Raspberry Pi que haya en el cluster, con su correspondiente nombre de host y dirección IP. En este caso, el archivo ```~/.ssh/config```de todas las Raspberry Pi luce de la siguiente manera:\n",
    "\n",
    "```Host master```   \n",
    "```User pi```  \n",
    "```Hostname 192.168.1.101```\n",
    "\n",
    "```Host slave01```   \n",
    "```User pi```  \n",
    "```Hostname 192.168.1.102```\n",
    "\n",
    "```Host slave02```   \n",
    "```User pi```  \n",
    "```Hostname 192.168.1.103```\n",
    "\n",
    "\n",
    "### Creación de llaves SSH\n",
    "\n",
    "Para simplificar la conexión SSH entre las Raspberry Pi, crearemos lo que se conoce como un par de _llaves SSH_, que se utilizarán para establecer una conexión por este medio entre las Raspberry Pi sin necesidad de escribir una contraseña. \n",
    "\n",
    "En cada una de las Raspberry Pi, teclee el siguiente comando:\n",
    "```ssh-keygen -t ed25519```  \n",
    "el cual generará este par de llaves, la _llave privada, almacenada en el archivo ```id_ed25519```, y la _llave pública_, almacenada en el archivo ```id_ed25519.pub```.\n",
    "\n",
    "Utilizaremos únicamente la llave pública, la llave privada no debe ser copiada ni movida a ningún otro dispositivo diferente al que la generó. \n",
    "\n",
    "Al igual que con los alias SSH, cada una de las Raspberry Pi deberá tener guardadas todas las llaves públicas del cluster en el archivo ```~/.ssh/authorized_keys```. Comencemos en el nodo _master_, agregando su proía llave pública al archivo mencionado anteriormente. Esto se puede hacer con el comando \n",
    "\n",
    "```cat .ssh/id_ed25519.pub >> .ssh/authorized_keys```.\n",
    "\n",
    "Ahora, podemos agregar las llaves públicas del resto de las Raspberry Pi mediante una conexión SSH, utilizando el comando  \n",
    "\n",
    "```cat ~/.ssh/id_ed25519.pub | ssh pi@192.168.1.10X 'cat >> .ssh/authorized_keys'```. \n",
    "\n",
    "Sustituyendo la _X_ para obtener las diferentes direcciones IP del cluster. Esto **concatena** el contenido del archivo de llave pública de la otra Raspberry Pi al archivo ```authorized_keys``` del nodo _master_. Repita este paso hasta obtener todas las llaves públicas del cluster.Una vez completado este paso, puede simplemente usar el comando  \n",
    "\n",
    "```cat .ssh/authorized_keys | ssh pi@192.168.1.101 'cat >> .ssh/authorized_keys'```  \n",
    "\n",
    "desde las otras Raspberry Pi para que copien el archivo ```authorized_keys``` del nodo _master_.\n",
    "\n",
    "Ahora es posible hacer una conexión SSH únicamente tecleando, por ejemplo, ```ssh slave01```.\n",
    "\n",
    "### Comandos de cluster útiles\n",
    "\n",
    "Ahora implementaremos algunos comandos que pueden resultar últiles a la hora de trabajar con el cluster. \n",
    "\n",
    "Para agregarlos, deberá acceder al archivo ```~/.bashrc``` con el comando ```nano ~/.bashrc```desde el nodo _master_.\n",
    "\n",
    "#### Mostrar el _hostname_ de todas las Raspberry Pi\n",
    "Navegue hasta el final del archivo ```~/.bashrc``` y agregue las siguientes líneas:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "function clusterreboot {\n",
    "  clustercmd sudo shutdown -r now\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enviar el mismo comando a todas las Raspberry Pi\n",
    "\n",
    "Para esto utilizaremos la función _otherpis_ creada anteriormente. En el mismo archivo ```~/.bashrc```, agregue las siguientes líneas:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "function clustercmd {\n",
    "  for pi in $(otherpis); do ssh $pi \"$@\"; done\n",
    "  $@\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reiniciar el cluster\n",
    "\n",
    "Cree la siguiente función en el archivo ```~/.bashrc```:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "function clusterreboot {\n",
    "  clustercmd sudo shutdown -r now\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apagar el cluster\n",
    "\n",
    "Añada la siguiente función al archivo ```~/.bashrc```:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "function clustershutdown {\n",
    "  clustercmd sudo shutdown now\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enviar el mismo archivo a todas las Raspberry Pi\n",
    "\n",
    "Añada la siguiente función al archivo ```~/.bashrc```:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "function clusterscp {\n",
    "  for pi in $(otherpis); do\n",
    "    cat $1 | ssh $pi \"sudo tee $1\" > /dev/null 2>&1\n",
    "  done\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos utilizar la función  ```clusterscp``` creada en el paso anterior para transferir el resto de las funciones creadas a todas las Raspberry Pi del cluster de la siguiente manera:\n",
    "\n",
    " ```source ~/.bashrc && clusterscp ~/.bashrc```\n",
    " \n",
    "### Hadoop y Spark. Instalación y configuración\n",
    "\n",
    "#### Verificar versión de Java\n",
    "\n",
    "En este caso se instalará la versión 3.2.1 de Hadoop, la cual requiere Java 7 o una versión superior. \n",
    "Compruebe la versión de java instalada actualmente con el comando\n",
    "\n",
    "```java -version```\n",
    "\n",
    "**Nota:** Asegúrese de que todas las Raspberry Pi cuenten con la misma versión de Java, ya que sólo se hará la confuguración en una de ellas y se copiará al resto del cluster. \n",
    "\n",
    "#### Obtener Hadoop\n",
    "\n",
    "Lo primero será realizar una configuración de cluster de un solo. En el nodo master, descargue Hadoop tecleando el siguiente comando:\n",
    "\n",
    "```cd && wget http://apache.mirrors.lucidnetworks.net/hadoop/common/hadoop-3.2.1/hadoop-3.2.1.tar.gz```  \n",
    "\n",
    "**Nota:** En caso de que no se logre reconocer el enlace o desee instalar una versión de Hadoop diferente, ingrese a la [página de descargas de Hadoop](http://apache.mirrors.lucidnetworks.net/hadoop/common/), copie el enlace de descarga de la versión de su preferencia y modifique el comando anterior reemplazando el enlace después del _wget_ por el de la otra versión.\n",
    "\n",
    "Una vez descargado Hadoop, ingrese los siguientes comandos:\n",
    "\n",
    "```sudo tar -xvf hadoop-3.2.1.tar.gz -C /opt/```  \n",
    "```rm 2wa3Hty && cd /opt```  \n",
    "```sudo mv hadoop-3.2.1 hadoop```  \n",
    "\n",
    "para instalarlo, asignarle un directorio y eliminar el archivo de instalación. \n",
    "\n",
    "Ingrese el comando  \n",
    "```sudo chown pi:pi -R /opt/hadoop```  \n",
    "para modificar los permisos de ese directorio.\n",
    "\n",
    "Después, agregue el directorio anterior al ```$PATH``` agregando las siguientes líneas al final del archivo ```~/.bashrc```\n",
    "\n",
    "```export JAVA_HOME=$ /usr/lib/jvm/java-8-openjdk-armhf/```  \n",
    "```export HADOOP_HOME=/opt/hadoop```  \n",
    "```export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin```\n",
    "\n",
    "**Nota:** La primera línea, donde se menciona ```JAVA_HOME``` puede variar dependiendo de la ubicación donde tenga instalado Java. Si no se reconoce la ruta del comando anterior, sólo sustituya dicha ruta por la ruta donde tenga Java instalado. Esto lo puede consultar con el comando\n",
    "\n",
    "```sudo update-alternatives --config java```\n",
    "\n",
    "Finalmente, agregue la siguiente línea al archivo ```/opt/hadoop/etc/hadoop/hadoop-env.sh```\n",
    "\n",
    "```export JAVA_HOME=$ /usr/lib/jvm/java-8-openjdk-armhf/```  \n",
    "\n",
    "Puede verificar que Hadoop se instaló correctamente con el comando\n",
    "\n",
    "```hadoop version | grep Hadoop```\n",
    "\n",
    "![hadoop_ver](https://github.com/RD13p/Proyecto_DataLake/blob/master/hadoop_ver.png?raw=true)\n",
    "\n",
    "#### Obtener Spark\n",
    "\n",
    "Descargue Spark ingresando el comando\n",
    "\n",
    "```cd && wget http://apache.mirrors.lucidnetworks.net/spark/spark-2.4.6/SparkR_2.4.6.tar.gz```  \n",
    "\n",
    "**Nota:** Al igual que con Hadoop, puede instalar otra versión de Spark ingresando a la [página de descargas de Spark](http://apache.mirrors.lucidnetworks.net/spark/) y copiando el enlace de la versión que desee. \n",
    "\n",
    "Posteriormente, ingrese los siguientes comandos: \n",
    "\n",
    "```sudo tar –xvf SparkR_2.4.6.tar.gz –C /opt/```  \n",
    "```rm SparkR_2.4.6.tar.gz && cd /opt```  \n",
    "```sudo mv spark-2.4.3-bin-hadoop2.7 spark```\n",
    "\n",
    "Modifique los permisos en este directorio\n",
    "\n",
    "```sudo chown pi:pi -R /opt/spark``` \n",
    "\n",
    "y agréguelo al ```$PATH``` añadiendo las siguientes líneas al final del archivo ```~/.bashrc```\n",
    "\n",
    "```export SPARK_HOME=/opt/spark```  \n",
    "```export PATH=$PATH:$SPARK_HOME/bin```\n",
    "\n",
    "Puede verificar que Spark se instaló correctamente con el comando\n",
    "\n",
    "```spark-shell --version``` \n",
    "\n",
    "![spark_ver](https://github.com/RD13p/Proyecto_DataLake/blob/master/spark_ver.png?raw=true)\n",
    "\n",
    "#### Configurar HDFS\n",
    "\n",
    "Para este paso es necesario modificar varios archivos de configuración ubicados en ```/opt/hadoop/etc/hadoop```  \n",
    "Ingrese al archivo **core-site.xml** y edite la configuración de la siguiente manera:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<configuration>\n",
    "  <property>\n",
    "    <name>fs.defaultFS</name>\n",
    "    <value>hdfs://master:9000</value>\n",
    "  </property>\n",
    "</configuration>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora modifique el archivo **hdfs-site.xml** de la siguiente forma:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<configuration>\n",
    "  <property>\n",
    "    <name>dfs.datanode.data.dir</name>\n",
    "    <value>file:///opt/hadoop_tmp/hdfs/datanode</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>dfs.namenode.name.dir</name>\n",
    "    <value>file:///opt/hadoop_tmp/hdfs/namenode</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>dfs.replication</name>\n",
    "    <value>1</value>\n",
    "  </property>\n",
    "</configuration>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cree los siguientes directorios:\n",
    "\n",
    "```sudo mkdir -p /opt/hadoop_tmp/hdfs/datanode```  \n",
    "```sudo mkdir -p /opt/hadoop_tmp/hdfs/namenode```\n",
    "\n",
    "Y ajuste los permisos\n",
    "```sudo chown pi:pi -R /opt/hadoop_tmp```  \n",
    "\n",
    "Posteriormente, diríjase al archivo **mapred-site.xml** y editelo de la siguiente manera:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<configuration>\n",
    "  <property>\n",
    "    <name>mapreduce.framework.name</name>\n",
    "    <value>yarn</value>\n",
    "  </property>\n",
    "</configuration>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y por último, edite el archivo **yarn-site.xml**:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<configuration>\n",
    "  <property>\n",
    "    <name>yarn.nodemanager.aux-services</name>\n",
    "    <value>mapreduce_shuffle</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>yarn.nodemanager.auxservices.mapreduce.shuffle.class</name>  \n",
    "    <value>org.apache.hadoop.mapred.ShuffleHandler</value>\n",
    "  </property>\n",
    "</configuration>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez modificados todos esos archivos, haremos un formateo del HDFS con el comando:\n",
    "\n",
    "```hdfs namenode -format -force```  \n",
    "\n",
    "E inicie HDFS y Yarn con el comando\n",
    "\n",
    "```start-dfs.sh && start-yarn.sh```\n",
    "\n",
    "Puede verificar que está funcionando correctamente con el comando ```jps```, donde debería obtener una salida parecida a esta:\n",
    "\n",
    "2736 NameNode\n",
    "2850 DataNode\n",
    "3430 NodeManager\n",
    "3318 ResourceManager\n",
    "3020 SecondaryNameNode\n",
    "3935 Jps\n",
    "\n",
    "### Configuración del cluster\n",
    "\n",
    "Con los pasos anteriores lo que se obtuvo es un cluster de un solo nodo conformado por el nodo _master_, el cual desempeñaba la función de maestro y trabajador al mismo tiempo. Ahora, configuraremos el resto de las Raspberry Pi como trabajadores. \n",
    "\n",
    "#### Creación de directorios\n",
    "\n",
    "Cree los siguientes directorios en todas las Raspberry Pi con los siguientes comandos:\n",
    "\n",
    "```clustercmd sudo mkdir -p /opt/hadoop_tmp/hdfs```  \n",
    "```clustercmd sudo chown pi:pi –R /opt/hadoop_tmp```  \n",
    "```clustercmd sudo mkdir -p /opt/hadoop```  \n",
    "```clustercmd sudo chown pi:pi /opt/hadoop```\n",
    "\n",
    "#### Copia de la configuración\n",
    "\n",
    "Ahora, copie todos los archivos ubicados en el directorio _/opt/hadoop_ del nodo maestro con el comando\n",
    "\n",
    "```for pi in $(otherpis); do rsync –avxP $HADOOP_HOME $pi:/opt; done```  \n",
    "\n",
    "Después, copie la configuración del archivo _.bashrc_ del nodo maestro al resto del cluster con los comandos\n",
    "\n",
    "```clusterscp .bashrc```  \n",
    "```clustercmd source .bashrc```  \n",
    "\n",
    "Una vez terminado este proceso, verifique que Hadoop fue instalado correctamente en todas las Raspberry Pi con el comando\n",
    "\n",
    "```clustercmd hadoop version | grep Hadoop```\n",
    "\n",
    "#### Configuración de Hadoop en el cluster\n",
    "\n",
    "Para tener HDFS funcionando en el cluster, es nocesario volver a modificar algunos archivos utilizados anteriormente. \n",
    "\n",
    "Ingrese al archivo ```core-site.xml``` con el comando\n",
    "\n",
    "```nano /opt/hadoop/etc/hadoop/core-site.xml```\n",
    "\n",
    "y edítelo de forma que quede de la siguiente manera:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<configuration>\n",
    "  <property>\n",
    "    <name>fs.default.name</name>\n",
    "    <value>hdfs://master:9000</value>\n",
    "  </property>\n",
    "</configuration>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posteriormente, edite el archivo ```hdfs-site.xml``` tecleando\n",
    "\n",
    "```nano /opt/hadoop/etc/hadoop/hdfs-site.xml```"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<configuration>\n",
    "  <property>\n",
    "    <name>dfs.datanode.data.dir</name>\n",
    "    <value>/opt/hadoop_tmp/hdfs/datanode</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>dfs.namenode.name.dir</name>\n",
    "    <value>/opt/hadoop_tmp/hdfs/namenode</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>dfs.replication</name>\n",
    "    <value>4</value>\n",
    "  </property>\n",
    "</configuration> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después, ingrese al archivo ```mapred-site.xml```\n",
    "\n",
    "```nano /opt/hadoop/etc/hadoop/mapred-site.xml```  \n",
    "\n",
    "y edítelo de la siguiente manera:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<configuration>\n",
    "  <property>\n",
    "    <name>mapreduce.framework.name</name>\n",
    "    <value>yarn</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>yarn.app.mapreduce.am.resource.mb</name>\n",
    "    <value>256</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>mapreduce.map.memory.mb</name>\n",
    "    <value>128</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>mapreduce.reduce.memory.mb</name>\n",
    "    <value>128</value>\n",
    "  </property>\n",
    "</configuration> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y finalmente, edite el archivo ```yarn-site.xml```\n",
    "\n",
    "```nano /opt/hadoop/etc/hadoop/yarn-site.xml```  \n",
    "\n",
    "de la siguiente manera:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<configuration>\n",
    "  <property>\n",
    "    <name>yarn.acl.enable</name>\n",
    "    <value>0</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>yarn.resourcemanager.hostname</name>\n",
    "    <value>master</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>yarn.nodemanager.aux-services</name>\n",
    "    <value>mapreduce_shuffle</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>yarn.nodemanager.auxservices.mapreduce.shuffle.class</name>  \n",
    "    <value>org.apache.hadoop.mapred.ShuffleHandler</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>yarn.nodemanager.resource.memory-mb</name>\n",
    "    <value>900</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>yarn.scheduler.maximum-allocation-mb</name>\n",
    "    <value>900</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>yarn.scheduler.minimum-allocation-mb</name>\n",
    "    <value>64</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>yarn.nodemanager.vmem-check-enabled</name>\n",
    "    <value>false</value>\n",
    "  </property>\n",
    "</configuration>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez modificados estos archivos, cópielos al resto de las Raspberry Pi con los comandos\n",
    "\n",
    "```clusterscp /opt/hadoop/etc/hadoop/yarn-site.xml```  \n",
    "```clusterscp /opt/hadoop/etc/hadoop/mapred-site.xml```  \n",
    "```clusterscp /opt/hadoop/etc/hadoop/core-site.xml```  \n",
    "```clusterscp /opt/hadoop/etc/hadoop/hdfs-site.xml```  \n",
    "\n",
    "Y limpie los directorios de los archivos temporales con los comandos:\n",
    "\n",
    "```clustercmd rm –rf /opt/hadoop_tmp/hdfs/datanode/*```  \n",
    "```clustercmd rm –rf /opt/hadoop_tmp/hdfs/namenode/*```  \n",
    "\n",
    "Posteriormente, navegue hasta ```$HADOOP_HOME/etc/hadoop/``` y cree un archivo llamado _master_\n",
    "\n",
    "```cd $HADOOP_HOME/etc/hadoop/```  \n",
    "```touch master```\n",
    "\n",
    "En este archivo se agregará únicamente el nombre del host maestro en el cluster, en este caso\n",
    "\n",
    "```master```\n",
    "\n",
    "Una vez creado y modificado este archivo, cree en ese mismo directorio otro archivo, esta vez con el nombre de __workers__\n",
    "\n",
    "```touch workers```  \n",
    "\n",
    "En ese archivo, agregue los nombres de host de las Raspberry Pi con el rol de trabajador, es decir, todo el cluster exceptuando al nodo _master_ agregado anteriormente al otro archivo\n",
    "\n",
    "```slave01```  \n",
    "```slave02```  \n",
    "\n",
    "Posteriormente, ingrese al archivo ```/etc/hosts``` con el comando ```cp``` y elimine la línea\n",
    "\n",
    "```127.0.0.1 raspberrypi```\n",
    "\n",
    "y copie este archivo ya modificado al resto del cluster con\n",
    "\n",
    "```clusterscp /etc/hosts```\n",
    "\n",
    "Una vez hecho esto, reinicie el cluster\n",
    "\n",
    "```clusterreboot```  \n",
    "\n",
    "para que los cambios hagan efecto. Una vez reiniciado el cluster, haga un formateo del HDFS con\n",
    "\n",
    "```hdfs namenode -format -force```  \n",
    "\n",
    "e inicie HDFS con el comando\n",
    "\n",
    "```start-dfs.sh && start-yarn.sh```  \n",
    "\n",
    "Verifique que el cluster está funcionando correctamente ingresando a la siguiente URL en su navegador\n",
    "\n",
    "http://192.168.1.101:9870\n",
    "\n",
    "esta dirección IP es la asignada al nodo maestro.\n",
    "\n",
    "![web_cluster](https://github.com/RD13p/Proyecto_DataLake/blob/master/web-cluster.png?raw=true)\n",
    "\n",
    "\n",
    "#### Configuración de Spark en el cluster\n",
    "\n",
    "El primer paso será ingresar al archivo ```.bashrc```con el comando ```cd``` y agregar las siguientes líneas:\n",
    "\n",
    "```export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop```  \n",
    "```export LD_LIBRARY_PATH=$HADOOP_HOME/lib/native:$LD_LIBRARY_PATH```  \n",
    "\n",
    "Ahora, ingrese al archivo de configuración de Spark\n",
    "\n",
    "```cd $SPARK_HOME/conf```\n",
    "```sudo mv spark-defaults.conf.template spark-defaults.conf```\n",
    "\n",
    "y agregue las siguientes líneas al final del archivo\n",
    "\n",
    "```spark.master            yarn```  \n",
    "```spark.driver.memory     465m```  \n",
    "```spark.yarn.am.memory    356m```  \n",
    "```spark.executor.memory   465m```  \n",
    "```spark.executor.cores    4```  \n",
    "\n",
    "Y para que estos cambios tomen efecto, reinicie el cluster.\n",
    "\n",
    "**Nota:** Ahora, será necesario que antes de reiniciar o apagar el cluster, ingrese el comando ```stop-dfs.sh && stop-yarn.sh```para detener HDFS, y lo mismo cada que el cluster encienda, pero con la palabra _start_ para arrancar HDFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
